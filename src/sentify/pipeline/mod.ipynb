{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "import sklearn.model_selection as skms\n",
    "import sklearn.preprocessing as skp\n",
    "import os\n",
    "import librosa\n",
    "import joblib \n",
    "import keras as k\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testPath = \"D:/WorkSpace/Projects/Sentify/artifacts/Audio\"\n",
    "scalerPath = \"D:/WorkSpace/Projects/Sentify/artifacts/abc.pkl\"\n",
    "modelPath = \"D:/WorkSpace/Projects/Sentify/artifacts/best_model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(librosa.load(testPath + \"/115.wav\", sr=44100, offset=0.5, res_type='kaiser_fast')[0]) // (2*44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "sample_rate = 44100\n",
    "\n",
    "factor = 2\n",
    "def loadAudio(fp):\n",
    "    return librosa.load(fp, res_type='kaiser_fast', offset=0.5, sr=sample_rate)\n",
    "\n",
    "def scanFeatures(path, avgFeat):\n",
    "    features = []\n",
    "    # minFeat = sys.maxsize\n",
    "    # maxFeat = 0\n",
    "    files = sorted(os.listdir(path))\n",
    "    print(\"Scanning\", path)\n",
    "\n",
    "    X, _ = loadAudio(os.path.join(path, path+'/'+files[0]))\n",
    "\n",
    "    for i in range(ceil(len(X) / (factor*sample_rate))):\n",
    "        f = librosa.feature.melspectrogram(y=X[factor*sample_rate*i:factor*sample_rate*(i+1)], sr=sample_rate)\n",
    "        f = librosa.amplitude_to_db(f, ref=np.max)\n",
    "\n",
    "    #         shapeY = f.shape[1]\n",
    "    #         if shapeY < minFeat:\n",
    "    #             minFeat = shapeY\n",
    "\n",
    "    #         if shapeY > maxFeat:\n",
    "    #             maxFeat = shapeY\n",
    "\n",
    "        features.append(f)\n",
    "    # if avgFeat == 0:\n",
    "    #     avgFeat = int((minFeat+maxFeat)/2)\n",
    "    feat_mat = np.zeros((ceil(len(X) / (factor*sample_rate)), f.shape[0], avgFeat))\n",
    "    for i, x in enumerate(features):\n",
    "        xWidth = min(x.shape[1],avgFeat)\n",
    "        feat_mat[i, :, :xWidth] = x[:,:xWidth]\n",
    "    return feat_mat, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning D:/WorkSpace/Projects/Sentify/artifacts/Audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 0.23.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000264904BE050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 978ms/step\n",
      "[[0.17523971 0.4948499  0.3299104 ]\n",
      " [0.09084634 0.8730912  0.03606248]]\n"
     ]
    }
   ],
   "source": [
    "test_data, test_files = scanFeatures(testPath, 128)\n",
    "\n",
    "# scaler = joblib.load(scalerPath)\n",
    "with open(scalerPath, \"rb\") as file:\n",
    "    scaler = pickle.load(file)\n",
    "scaler.clip = False\n",
    "\n",
    "test_data = scaler.transform(test_data.reshape(-1, test_data.shape[-1])).reshape(test_data.shape)\n",
    "\n",
    "predict = k.models.load_model(modelPath).predict(test_data)\n",
    "\n",
    "# Negative, Neutral, Positive\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pickle \n",
    "import librosa \n",
    "\n",
    "\n",
    "testPath = \"D:/WorkSpace/Projects/Sentify/artifacts/Audio\"\n",
    "scalerPath = \"D:/WorkSpace/Projects/Sentify/artifacts/abc.pkl\"\n",
    "modelPath = \"D:/WorkSpace/Projects/Sentify/artifacts/best_model.hdf5\"\n",
    "\n",
    "\n",
    "class AudioSentiment:\n",
    "    def __init__(self, test_path: str = testPath, \n",
    "                 scaler_path: str = scalerPath, model_path:str =  modelPath):\n",
    "        self.test_path = test_path \n",
    "        self.scaler_path = scaler_path\n",
    "        self.model_path = model_path\n",
    "    \n",
    "    def predict(self):\n",
    "        test_data, _ = self.__scanFeatures(testPath, 128)\n",
    "\n",
    "        with open(self.scaler_path, \"rb\") as file:\n",
    "            scaler = pickle.load(file)\n",
    "        scaler.clip = False\n",
    "\n",
    "        test_data = scaler.transform(test_data.reshape(-1, test_data.shape[-1])).reshape(test_data.shape)\n",
    "\n",
    "        predict = k.models.load_model(modelPath).predict(test_data)\n",
    "        \n",
    "        return predict\n",
    "        \n",
    "    def __scanFeatures(path, avgFeat):\n",
    "        features = []\n",
    "\n",
    "        files = sorted(os.listdir(path))\n",
    "        print(\"Scanning\", path)\n",
    "\n",
    "        X, _ = loadAudio(os.path.join(path, path+'/'+files[0]))\n",
    "\n",
    "        for i in range(ceil(len(X) / (factor*sample_rate))):\n",
    "            f = librosa.feature.melspectrogram(y=X[factor*sample_rate*i:factor*sample_rate*(i+1)], sr=sample_rate)\n",
    "            f = librosa.amplitude_to_db(f, ref=np.max)\n",
    "\n",
    "            features.append(f)\n",
    "\n",
    "        feat_mat = np.zeros((ceil(len(X) / (factor*sample_rate)), f.shape[0], avgFeat))\n",
    "        for i, x in enumerate(features):\n",
    "            xWidth = min(x.shape[1],avgFeat)\n",
    "            feat_mat[i, :, :xWidth] = x[:,:xWidth]\n",
    "        return feat_mat, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "dataset = pd.read_csv('../../../artifacts/data/sentiment-emotion-labelled_Dell_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# text = \"Good morning\"\n",
    "translator = GoogleTranslator(source='auto', target='pa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n",
      "3280\n",
      "3290\n",
      "3300\n",
      "3310\n",
      "3320\n",
      "3330\n",
      "3340\n",
      "3350\n",
      "3360\n",
      "3370\n",
      "3380\n",
      "3390\n",
      "3400\n",
      "3410\n",
      "3420\n",
      "3430\n",
      "3440\n",
      "3450\n",
      "3460\n",
      "3470\n",
      "3480\n",
      "3490\n",
      "3500\n",
      "3510\n",
      "3520\n",
      "3530\n",
      "3540\n",
      "3550\n",
      "3560\n",
      "3570\n",
      "3580\n",
      "3590\n",
      "3600\n",
      "3610\n",
      "3620\n",
      "3630\n",
      "3640\n",
      "3650\n",
      "3660\n",
      "3670\n",
      "3680\n",
      "3690\n",
      "3700\n",
      "3710\n",
      "3720\n",
      "3730\n",
      "3740\n",
      "3750\n",
      "3760\n",
      "3770\n",
      "3780\n",
      "3790\n",
      "3800\n",
      "3810\n",
      "3820\n",
      "3830\n",
      "3840\n",
      "3850\n",
      "3860\n",
      "3870\n",
      "3880\n",
      "3890\n",
      "3900\n",
      "3910\n",
      "3920\n",
      "3930\n",
      "3940\n",
      "3950\n",
      "3960\n",
      "3970\n",
      "3980\n",
      "3990\n",
      "4000\n",
      "4010\n",
      "4020\n",
      "4030\n",
      "4040\n",
      "4050\n",
      "4060\n",
      "4070\n",
      "4080\n",
      "4090\n",
      "4100\n",
      "4110\n",
      "4120\n",
      "4130\n",
      "4140\n",
      "4150\n",
      "4160\n",
      "4170\n",
      "4180\n",
      "4190\n",
      "4200\n",
      "4210\n",
      "4220\n",
      "4230\n",
      "4240\n",
      "4250\n",
      "4260\n",
      "4270\n",
      "4280\n",
      "4290\n",
      "4300\n",
      "4310\n",
      "4320\n",
      "4330\n",
      "4340\n",
      "4350\n",
      "4360\n",
      "4370\n",
      "4380\n",
      "4390\n",
      "4400\n",
      "4410\n",
      "4420\n",
      "4430\n",
      "4440\n",
      "4450\n",
      "4460\n",
      "4470\n",
      "4480\n",
      "4490\n",
      "4500\n",
      "4510\n",
      "4520\n",
      "4530\n",
      "4540\n",
      "4550\n",
      "4560\n",
      "4570\n",
      "4580\n",
      "4590\n",
      "4600\n",
      "4610\n",
      "4620\n",
      "4630\n",
      "4640\n",
      "4650\n",
      "4660\n",
      "4670\n",
      "4680\n",
      "4690\n",
      "4700\n",
      "4710\n",
      "4720\n",
      "4730\n",
      "4740\n",
      "4750\n",
      "4760\n",
      "4770\n",
      "4780\n",
      "4790\n",
      "4800\n",
      "4810\n",
      "4820\n",
      "4830\n",
      "4840\n",
      "4850\n",
      "4860\n",
      "4870\n",
      "4880\n",
      "4890\n",
      "4900\n",
      "4910\n",
      "4920\n",
      "4930\n",
      "4940\n",
      "4950\n",
      "4960\n",
      "4970\n",
      "4980\n",
      "4990\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "# hindi_texts = []\n",
    "punjabi_texts = []\n",
    "\n",
    "samp_dataset = dataset.sample(frac=0.2)\n",
    "for seq in samp_dataset.iloc[:, 3]:\n",
    "    punjabi_texts.append(translator.translate(seq))\n",
    "    # punjabi_texts.append(punjabi.translate(seq))\n",
    "    \n",
    "    count += 1\n",
    "    if count % 10==0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_dataset = samp_dataset[['sentiment', 'emotion']]\n",
    "samp_dataset['Text'] = punjabi_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_dataset.to_csv(\"punjabi_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
